{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ICT707 Task 1 Test\n",
    "\n",
    "\n",
    "### Instructions\n",
    "\n",
    "* This assignment will be done completely inside this Jupyter notebook.\n",
    "* You have 5 tasks worth of 20 marks to complete in this Notebook.\n",
    "\n",
    "* **Write your answers to the space between ### BEGIN SOLUTION   and   ### END SOLUTION**.\n",
    "\n",
    "* **You need to upload this notebook template and two data set files to the server**.\n",
    "* **You have 120 minutes.**\n",
    "* **After you finish, make sure all cells are executed. Go to menu \"File->Download as\" to download your work as 2 files: (1) a Jupyter notebook file and (2) a HTML file. And then submit both files to Blackboard.**\n",
    "\n",
    "* If you see any error related to spark context, please **run the last cell** and then retry.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Please enter your NAME and student ID\n",
    "NAME = \"GAGANDEEP KAUR\"\n",
    "ID = \"1121869\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PART I: Use Spark to process text files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1: [2 marks] Get the spark context ready"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add imports here\n",
    "\n",
    "### BEGIN SOLUTION\n",
    "from pyspark import SparkContext\n",
    "### END SOLUTION\n",
    "\n",
    "\n",
    "# create SparkContext\n",
    "\n",
    "### BEGIN SOLUTION\n",
    "sc = SparkContext(\"local\",\"test app\")\n",
    "### END SOLUTION\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2: [4 marks] Load the file and count the word frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "221"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the text file \"Alice_Adventures_in_Wonderland.txt\" into variable file_rdd\n",
    "\n",
    "### BEGIN SOLUTION\n",
    "file_rdd=sc.textFile(\"Alice_Adventures_in_Wonderland.txt\")\n",
    "### END SOLUTION\n",
    "\n",
    "# print the number of lines containing word \"Alice\" ignoring the case\n",
    "\n",
    "### BEGIN SOLUTION\n",
    "file_rdd.filter(lambda x: \"Alice\" in x.split()).count()\n",
    "\n",
    "### END SOLUTION\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PART II: Use Spark SQL to process structure data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3: [4 marks] load the csv file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Dataset:**\n",
    "\n",
    "In this test, we use a data set \"sales.csv\" which consists of the sale records at a shop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---------------+------+---+-----+------+------+---------+---------+------+\n",
      "|CustNum|           Name|   Sex|Age|State|Income|Clicks|LastSpend|Purchases| Spend|\n",
      "+-------+---------------+------+---+-----+------+------+---------+---------+------+\n",
      "|      0| Brandon Bender|  male| 67|  NSW|120000|   709|  2488.59|        8|1615.0|\n",
      "|      1|Andre Mccormick|  male| 38|  VIC|140000|   630|  4295.34|       14|1927.2|\n",
      "|      2|   Ashley Smith|female| 47|  NSW| 50000|   554|  1986.09|        8|1660.8|\n",
      "|      3|      Ann Riley|female| 33|  NSW|100000|   309|  1532.64|       10|3041.1|\n",
      "|      4| Timothy Chavez|  male| 49|  NSW|140000|   520|  2082.08|        8|1764.4|\n",
      "+-------+---------------+------+---+-----+------+------+---------+---------+------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# add imports here\n",
    "from pyspark.sql import SQLContext\n",
    "\n",
    "# create SQLContext. Keep in mind that we have already created SparkContext sc\n",
    "\n",
    "### BEGIN SOLUTION\n",
    "sqlContext = SQLContext(sc)\n",
    "### END SOLUTION\n",
    "\n",
    "# load load the csv file \"sales.csv\" into variable data_df\n",
    "\n",
    "### BEGIN SOLUTION\n",
    "data_df = sqlContext.read.csv(\"sales.csv\",header=True,inferSchema=True)\n",
    "### END SOLUTION\n",
    "\n",
    "data_df.show(5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 4: [4 marks] Selection and filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+------+-------+\n",
      "|Age|State|Income|  Spend|\n",
      "+---+-----+------+-------+\n",
      "| 19|  VIC| 30000| 596.75|\n",
      "| 21|  NSW| 50000| 946.05|\n",
      "| 21|  QLD|120000| 1844.9|\n",
      "| 25|  NSW|100000| 1280.0|\n",
      "| 28|  NSW|140000| 1779.8|\n",
      "| 30|  NSW|160000| 2895.0|\n",
      "| 31|   SA| 70000|1332.85|\n",
      "| 31|  NSW|160000| 2662.5|\n",
      "| 34|  NSW|140000| 1991.0|\n",
      "| 34|  QLD| 60000|  886.0|\n",
      "| 35|  QLD| 40000|  761.6|\n",
      "| 38|  VIC|140000| 1927.2|\n",
      "| 38|  NSW| 50000|  878.9|\n",
      "| 42|  VIC| 80000| 1471.6|\n",
      "| 42|   SA| 60000| 1065.0|\n",
      "| 42|  VIC| 20000|  428.4|\n",
      "| 43|  VIC|160000| 2480.0|\n",
      "| 44|  NSW| 50000| 981.75|\n",
      "| 45|  NSW| 90000| 1600.8|\n",
      "| 46|  QLD| 20000|  357.2|\n",
      "+---+-----+------+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Get \"Age\", \"State\", \"Income\", and \"Spend\" attributes for all male customers, and order them based on \"Age\"\n",
    "# Requirement: Use DataFrame DSL\n",
    "\n",
    "### BEGIN SOLUTION\n",
    "data_df.filter(data_df.Sex=='male').orderBy('Age').select('Age','State','Income','Spend').show()\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 5: [6 marks] Filtering and aggregation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----+\n",
      "|State|count|\n",
      "+-----+-----+\n",
      "|  ACT|    1|\n",
      "|   SA|    2|\n",
      "|  QLD|   11|\n",
      "|  VIC|   13|\n",
      "|  NSW|   31|\n",
      "+-----+-----+\n",
      "\n",
      "+-----+--------------+\n",
      "|State|count(CustNum)|\n",
      "+-----+--------------+\n",
      "|  ACT|             1|\n",
      "|   SA|             2|\n",
      "|  QLD|            11|\n",
      "|  VIC|            13|\n",
      "|  NSW|            31|\n",
      "+-----+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print the number of customers with \"Clicks\" greater than 500 for each state group.\n",
    "# Requirement: Use DataFrame DSL\n",
    "\n",
    "### BEGIN SOLUTION\n",
    "x=data_df.filter(data_df.Clicks>500).groupby('State')\n",
    "x.count().show()\n",
    "### END SOLUTION\n",
    "\n",
    "\n",
    "# Print the number of customers with \"Clicks\" greater than 500 for each state group.\n",
    "# Requirement: Use SQL statement\n",
    "\n",
    "### BEGIN SOLUTION\n",
    "data_df.registerTempTable('user_table')\n",
    "sqlContext.sql(\"\"\"SELECT State,COUNT(CustNum) FROM user_table WHERE Clicks > 500 GROUP BY State\"\"\").show()\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shut down SparkContext when exiting\n",
    "\n",
    "If you have error messages related to sparkContext, try to run the following cell, and then rerun all cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
