{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "name": "ICT707_2020S2_Task_3_Template_Colab.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JYggDOZMBiqc"
      },
      "source": [
        "# PySpark Environment Setting"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LoRLSnOtBXzn",
        "outputId": "4c5df1f9-2ab6-4550-df17-ade9ab89b902",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 683
        }
      },
      "source": [
        "# Please run this cell to get Java and spark installed\n",
        "!apt-get update\n",
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "!wget -q https://downloads.apache.org/spark/spark-2.4.7/spark-2.4.7-bin-hadoop2.7.tgz\n",
        "!tar xf spark-2.4.7-bin-hadoop2.7.tgz\n",
        "!pip install pyspark==2.4.7\n",
        "\n",
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-2.4.7-bin-hadoop2.7\"\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Get:1 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ InRelease [3,626 B]\n",
            "Ign:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n",
            "Ign:3 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n",
            "Get:4 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release [697 B]\n",
            "Hit:5 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n",
            "Get:6 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release.gpg [836 B]\n",
            "Get:7 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic InRelease [15.9 kB]\n",
            "Hit:9 http://archive.ubuntu.com/ubuntu bionic InRelease\n",
            "Get:10 http://security.ubuntu.com/ubuntu bionic-security InRelease [88.7 kB]\n",
            "Get:11 http://archive.ubuntu.com/ubuntu bionic-updates InRelease [88.7 kB]\n",
            "Ign:12 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Packages\n",
            "Get:12 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Packages [335 kB]\n",
            "Hit:13 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease\n",
            "Get:14 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic/main Sources [1,681 kB]\n",
            "Get:15 http://archive.ubuntu.com/ubuntu bionic-backports InRelease [74.6 kB]\n",
            "Get:16 http://security.ubuntu.com/ubuntu bionic-security/multiverse amd64 Packages [15.0 kB]\n",
            "Get:17 http://security.ubuntu.com/ubuntu bionic-security/universe amd64 Packages [1,348 kB]\n",
            "Get:18 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 Packages [2,150 kB]\n",
            "Get:19 http://archive.ubuntu.com/ubuntu bionic-updates/restricted amd64 Packages [231 kB]\n",
            "Get:20 http://security.ubuntu.com/ubuntu bionic-security/main amd64 Packages [1,733 kB]\n",
            "Get:21 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 Packages [2,112 kB]\n",
            "Get:22 http://archive.ubuntu.com/ubuntu bionic-updates/multiverse amd64 Packages [45.5 kB]\n",
            "Get:23 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic/main amd64 Packages [860 kB]\n",
            "Fetched 10.8 MB in 5s (2,020 kB/s)\n",
            "Reading package lists... Done\n",
            "Collecting pyspark==2.4.7\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e2/06/29f80e5a464033432eedf89924e7aa6ebbc47ce4dcd956853a73627f2c07/pyspark-2.4.7.tar.gz (217.9MB)\n",
            "\u001b[K     |████████████████████████████████| 217.9MB 67kB/s \n",
            "\u001b[?25hCollecting py4j==0.10.7\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e3/53/c737818eb9a7dc32a7cd4f1396e787bd94200c3997c72c1dbe028587bd76/py4j-0.10.7-py2.py3-none-any.whl (197kB)\n",
            "\u001b[K     |████████████████████████████████| 204kB 43.5MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-2.4.7-py2.py3-none-any.whl size=218279466 sha256=e240d316a72779f02f8491b3f5e94cdadafe58c202d1b6d60fd384265b69de67\n",
            "  Stored in directory: /root/.cache/pip/wheels/34/1f/2e/1e7460f80acf26b08dbb8c53d7ff9e07146f2a68dd5c732be5\n",
            "Successfully built pyspark\n",
            "Installing collected packages: py4j, pyspark\n",
            "Successfully installed py4j-0.10.7 pyspark-2.4.7\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jsr_Xl5LBVNr"
      },
      "source": [
        "# ICT707 Task 3\n",
        "## Please implement your assignment in this notebook.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "czZCbsXABVNs"
      },
      "source": [
        "# Please enter your NAME and student ID\n",
        "NAME = \"GAGANDEEP KAUR\"\n",
        "ID = \"1121869\""
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OF2ByTgJBnIE"
      },
      "source": [
        "# Connect GDrive for data set files"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "muPOGMTfBr2s",
        "outputId": "878218ba-fff0-4a7d-e125-73bdd397a014",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Mount the cloud folder for data file storage\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H0FqMLY0GEU_"
      },
      "source": [
        "# Make sure you have relevant data files uploaded\n",
        "# And then use the correct data file names below\n",
        "datafile = \"/content/gdrive/My Drive/Colab Notebooks/ratings.csv\""
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IxrL34e0BVNw"
      },
      "source": [
        "## PART I: EDA\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aFV1zQwVBVNx"
      },
      "source": [
        "# Code implementation\n",
        "from pyspark import SparkContext\n",
        "from pyspark.sql import SQLContext\n",
        "sc = SparkContext()\n",
        "sqlContext = SQLContext(sc)"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cYVOnGxPGiVh",
        "outputId": "f5525c1a-0da2-42c9-f614-e267053e6d30",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        }
      },
      "source": [
        "df = sqlContext.read.csv(datafile,header=True,inferSchema=True)\n",
        "df.show(10)\n",
        "print(\"Total number of Rows\",df.count())"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-------+-------+------+\n",
            "|book_id|user_id|rating|\n",
            "+-------+-------+------+\n",
            "|      1|    314|     5|\n",
            "|      1|    439|     3|\n",
            "|      1|    588|     5|\n",
            "|      1|   1169|     4|\n",
            "|      1|   1185|     4|\n",
            "|      1|   2077|     4|\n",
            "|      1|   2487|     4|\n",
            "|      1|   2900|     5|\n",
            "|      1|   3662|     4|\n",
            "|      1|   3922|     5|\n",
            "+-------+-------+------+\n",
            "only showing top 10 rows\n",
            "\n",
            "Total number of Rows 981756\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fP78KD94GINX",
        "outputId": "c86b4e6f-7e2a-43e1-90fa-b0d321ba6529",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "df = df.sample(withReplacement = False, \n",
        "                         fraction = 0.01, # 1% of observation\n",
        "                         seed = 2019)\n",
        "print(\"Total number of rows in current sample we are using\", df.count())"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total number of rows in current sample we are using 9899\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ltl2k5w_H2xG",
        "outputId": "c42a21c2-4152-423c-d000-0308b6e9f50d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "df.schema"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "StructType(List(StructField(book_id,IntegerType,true),StructField(user_id,IntegerType,true),StructField(rating,IntegerType,true)))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4PibPP-JGvnD",
        "outputId": "ffc04596-2a89-48ca-b92f-ad8055cd7ca9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "df.columns"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['book_id', 'user_id', 'rating']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SfQjbaS08L3l"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QQqKWtAoBVN2"
      },
      "source": [
        "## PART II:  Collaborative filtering with Alternative Least Squares Algorithm\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_k9JRvYPLqXe",
        "outputId": "ea770cfd-a512-4ec6-b4a5-4cda49daed93",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# Code implementation\n",
        "training, test=df.randomSplit([0.6, 0.4])\n",
        "print(\"number of rows in training dataset:\",training.count())\n",
        "print(\"number of rows in testing dataset:\",test.count())"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "number of rows in training dataset: 5943\n",
            "number of rows in testing dataset: 3956\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zsSSDuZiCPvN"
      },
      "source": [
        "from pyspark.ml.recommendation import ALS\n",
        "als=ALS(userCol=\"user_id\",itemCol=\"book_id\",ratingCol=\"rating\",\n",
        "        nonnegative=True,\n",
        "        coldStartStrategy=\"drop\",\n",
        "        implicitPrefs=False)\n",
        "als_model=als.fit(training)\n",
        "pred= als_model.transform(test)"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xwGpYd7TDEXC",
        "outputId": "beb6f891-d528-4a9a-c0c8-c73317fcbbbc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from pyspark.ml.evaluation import RegressionEvaluator\n",
        "evaluator = RegressionEvaluator(metricName=\"rmse\", labelCol=\"rating\",\n",
        "                                predictionCol=\"prediction\")\n",
        "rmse = evaluator.evaluate(pred)\n",
        "print (\"RMSE: \", rmse)\n"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "RMSE:  2.841999713901338\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rHWmiMheHdFR"
      },
      "source": [
        "## PART III:  Classification system with Logistic regression\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HI63f4vLtXNN",
        "outputId": "fa104e9e-1341-42bd-acc6-28e64deef12e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 459
        }
      },
      "source": [
        "vector_df=df.withColumn(\"label\",df.rating>3)\n",
        "vector_df.show()"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-------+-------+------+-----+\n",
            "|book_id|user_id|rating|label|\n",
            "+-------+-------+------+-----+\n",
            "|      1|  30681|     5| true|\n",
            "|      2|  14546|     5| true|\n",
            "|      3|   5885|     4| true|\n",
            "|      8|  17228|     4| true|\n",
            "|      8|  49288|     5| true|\n",
            "|     10|   9246|     2|false|\n",
            "|     10|  23612|     4| true|\n",
            "|     10|  39423|     3|false|\n",
            "|     10|  51166|     3|false|\n",
            "|     14|   8484|     3|false|\n",
            "|     14|  48559|     3|false|\n",
            "|     14|  51460|     3|false|\n",
            "|     17|   3922|     5| true|\n",
            "|     20|  24845|     3|false|\n",
            "|     21|   9771|     4| true|\n",
            "|     24|  16569|     4| true|\n",
            "|     24|  47800|     5| true|\n",
            "|     27|    439|     5| true|\n",
            "|     27|  19942|     4| true|\n",
            "|     27|  45554|     3|false|\n",
            "+-------+-------+------+-----+\n",
            "only showing top 20 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "42mPBkzPZpuE",
        "outputId": "5c21f678-899b-4ee7-b852-65ee414690b4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 459
        }
      },
      "source": [
        "from pyspark.ml.feature import VectorAssembler\n",
        "assembler=VectorAssembler().setInputCols([\"book_id\",\"user_id\",\"rating\"]).setOutputCol(\"features\")\n",
        "ml_df=assembler.transform(vector_df)\n",
        "ml_df=ml_df.select(ml_df.features,ml_df.label.astype('int'))\n",
        "ml_df.show()"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+------------------+-----+\n",
            "|          features|label|\n",
            "+------------------+-----+\n",
            "| [1.0,30681.0,5.0]|    1|\n",
            "| [2.0,14546.0,5.0]|    1|\n",
            "|  [3.0,5885.0,4.0]|    1|\n",
            "| [8.0,17228.0,4.0]|    1|\n",
            "| [8.0,49288.0,5.0]|    1|\n",
            "| [10.0,9246.0,2.0]|    0|\n",
            "|[10.0,23612.0,4.0]|    1|\n",
            "|[10.0,39423.0,3.0]|    0|\n",
            "|[10.0,51166.0,3.0]|    0|\n",
            "| [14.0,8484.0,3.0]|    0|\n",
            "|[14.0,48559.0,3.0]|    0|\n",
            "|[14.0,51460.0,3.0]|    0|\n",
            "| [17.0,3922.0,5.0]|    1|\n",
            "|[20.0,24845.0,3.0]|    0|\n",
            "| [21.0,9771.0,4.0]|    1|\n",
            "|[24.0,16569.0,4.0]|    1|\n",
            "|[24.0,47800.0,5.0]|    1|\n",
            "|  [27.0,439.0,5.0]|    1|\n",
            "|[27.0,19942.0,4.0]|    1|\n",
            "|[27.0,45554.0,3.0]|    0|\n",
            "+------------------+-----+\n",
            "only showing top 20 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E6ksV3yvrW9G"
      },
      "source": [
        "train, test= ml_df.randomSplit([0.8, 0.2])\n",
        "from pyspark.ml.classification import LogisticRegression\n",
        "lr = LogisticRegression(maxIter=10, regParam=0.3, elasticNetParam=0.8)\n",
        "lr_model=lr.fit(train)\n",
        "prediction=lr_model.transform(test)"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WuaoKN7Sw-r_"
      },
      "source": [
        "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
        "scored_test=lr_model.transform(test)\n",
        "scored_train=lr_model.transform(train)\n",
        "evaluator=BinaryClassificationEvaluator()"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iN3SrbwizLb5",
        "outputId": "59fd733d-782c-4362-c77f-9af3b216e08f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "evaluator.evaluate(scored_train,{evaluator.metricName:'areaUnderROC'})"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fXxj50mt0N-_",
        "outputId": "0e7de53a-d2c5-4d66-813b-8a4c380b8bc5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "evaluator.evaluate(scored_test,{evaluator.metricName:'areaUnderROC'})"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Inodh_mrBVN_"
      },
      "source": [
        "## Shut down SparkContext when exiting\n",
        "\n",
        "If you have error messages related to sparkContext, try to run the following cell, and then rerun all cells."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8IRm1qMaBVN_"
      },
      "source": [
        "sc.stop()"
      ],
      "execution_count": 28,
      "outputs": []
    }
  ]
}